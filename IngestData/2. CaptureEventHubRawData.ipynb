{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Raw Data from Event Hub into DataLake\n",
    "Event hubs can automatically save data into a table in a Gen 2 data lake. The event data gets stored as binary in the data lake. This means that no validation of the event data is performed on write so you are required to validate the data on reading instead. Validating the data on read also allows for different data formats and shapes to all be sent through the 1 event hub into the same data lake table. Filtering on read can then be applied to retrieve only the events you require. The Data Stored in this table is immutable and is owned by the event hub. The only way this data can be modified is the table being deleted when you delete the raw data capture from an event hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data gets saved to the data lake with the following schema.\n",
    "\n",
    "| SequenceNumber | Offset | EnqueuedTimeUtc | SystemProperties | Properties | Body   |\n",
    "|----------------|--------|-----------------|------------------|------------|--------|\n",
    "| Int            | String | DateTime        | Map              | Map        | Binary |\n",
    "\n",
    "The following optional columns may also exist depending on how you partition the data.\n",
    "\n",
    "| Year(Optional) | Month(Optional) | Day(Optional) | Hour(Optional) | PartitionId(Optional) |\n",
    "|----------------|-----------------|---------------|----------------|-----------------------|\n",
    "| Int            | Int             | Int           | Int            | String                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuro_python.neuro_data import endpoint_manager as epm, datastore_manager as dsm, schema_manager as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastores=[datastore['StoreName'] for datastore in dsm.list_data_stores()]\n",
    "datastores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the raw data capture\n",
    "Choose an appropriate datetime_partition_level to partition your data by datatime. For example DateTimeLevels.Day will cause data partitioning like Year=2020/Month=1/Day=19/... where as DateTimeLevels.Hour will result in Year=2020/Month=1/Day=19/Hour=13/... partition_id_level will allow your data to be grouped using the 32 partitions of the event hub (when sending data to an event hub you can choose the partition). For example DateTimeLevels.Day and PartitionIdLevels.Top will result in PartitionId=0/Year=2020/Month=1/Day=19/Hour=13/... where as bottom will result in Year=2020/Month=1/Day=19/Hour=13/PartitionId=0/... NOTE: PartitionIdLevels.Top is better suited if data in partition is normally looked at independently of each other while PartitionIdLevels.Bottom is better if multiple partitions are used in the same query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_name='sarikaTestworkspace1'\n",
    "event_hub_name='Hub1'\n",
    "datalake_name='LeeTestAdlsGen2v1'\n",
    "datetime_partition_level=epm.DateTimeLevels.Day\n",
    "partition_id_level=epm.PartitionIdLevels.Top\n",
    "epm.create_update_event_hub_raw_data_capture(namespace_name,event_hub_name,datalake_name,datetime_partition_level,partition_id_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(table for table in sm.list_tables(datalake_name) if table['TableName']=='NvEventHub%sRawData'%event_hub_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
