{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw landed data in an adhoc manner\n",
    "This will show you how to view and interpret raw landed data in an interactive way. This would generally only be used to verify data has landed and is valid. Once that is done a scheduled spark job should be setup to move the data into shape and format suitable for access (a wide table using delta as the format is suitable for most usecases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish spark interactive context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuro_python.neuro_compute import spark_manager as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.list_workspaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.list_clusters(workspace_id='e93714e3-1506-40a6-941d-50b808cf935c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.start_cluster(cluster_id='3ca51b3c-fdd2-4700-ae0d-79548cca85e8',workspace_id='e93714e3-1506-40a6-941d-50b808cf935c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.create_context(\"test1\",cluster_id='3ca51b3c-fdd2-4700-ae0d-79548cca85e8',workspace_id='e93714e3-1506-40a6-941d-50b808cf935c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure libraries are installed on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.list_libraries(cluster_id='3ca51b3c-fdd2-4700-ae0d-79548cca85e8',workspace_id='e93714e3-1506-40a6-941d-50b808cf935c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spm.install_library('neuro-python-clients','0.0.15',library_uri='https://pkgs.dev.azure.com/DownerD3S/b192675d-16a5-456b-8f8b-7fc483740331/_packaging/NeuroHelpers/pypi/simple/',cluster_id='3ca51b3c-fdd2-4700-ae0d-79548cca85e8',workspace_id='e93714e3-1506-40a6-941d-50b808cf935c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and initialise the chunk reader module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "from neuro_python_clients.pyspark import chunked_reader as cr\n",
    "cr.init(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the raw data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark_import_table\n",
    "import_table('df1','LeeTestGen2','NvEventHubHub1RawData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View raw data in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark_sql\n",
    "select *\n",
    "from df1\n",
    "where Day=8 and\n",
    "Month=4 and\n",
    "Year=2020 and\n",
    "PartitionId=0\n",
    "limit 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and reshape the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "part_dets=cr.PartitionDetails(0,2020,4,8)\n",
    "df2=cr.combine_chunked_messages_v1_4(df1,part_dets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark_pandas -df df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret binary reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "import json\n",
    "import pickle\n",
    "from pyspark.sql import functions as psf\n",
    "def pickle2json(bytedata):\n",
    "    return json.dumps(pickle.loads(bytedata))\n",
    "udf_pickle2json = psf.udf(pickle2json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "df3=df2.filter(df2.interfaceName==psf.lit('testInterface2')).select(udf_pickle2json(df2.binaryData).alias('json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%spark_pandas -df df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
