{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data necessary for the tutorials\n",
    "It is not expected that you will understand all aspects of this script (though reading through it is still suggested). You only need to change the datalake name and data store name below. Once you have done that simply run all cells in this script and the data will be available in your tenant. Note this script should only be run once in your tenant otherwise you will receive errors about tables already existing. The tables are shared across all users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Data Lake and SQL store name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalake_name='DataLakeName'\n",
    "sql_store_name='SqlStoreName'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the max temperature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o IDCJAC0010_009021_1800_Data.csv https://raw.githubusercontent.com/SnowdenNeuroverse/NeuroTraining/master/Data/PerthWeatherStationData/IDCJAC0010_009021_1800_Data.csv\n",
    "!curl -o IDCJAC0010_009106_1800_Data.csv https://raw.githubusercontent.com/SnowdenNeuroverse/NeuroTraining/master/Data/PerthWeatherStationData/IDCJAC0010_009106_1800_Data.csv\n",
    "!curl -o IDCJAC0010_009215_1800_Data.csv https://raw.githubusercontent.com/SnowdenNeuroverse/NeuroTraining/master/Data/PerthWeatherStationData/IDCJAC0010_009215_1800_Data.csv\n",
    "!curl -o IDCJAC0010_009225_1800_Data.csv https://raw.githubusercontent.com/SnowdenNeuroverse/NeuroTraining/master/Data/PerthWeatherStationData/IDCJAC0010_009225_1800_Data.csv\n",
    "!curl -o IDCJAC0010_009265_1800_Data.csv https://raw.githubusercontent.com/SnowdenNeuroverse/NeuroTraining/master/Data/PerthWeatherStationData/IDCJAC0010_009265_1800_Data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuro_python.neuro_data import schema_manager as sm\n",
    "from neuro_python.neuro_data import sql_commands as sc\n",
    "from neuro_python.neuro_data import sql_query as sq\n",
    "from neuro_python.neuro_compute import spark_manager as spm\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols=[sm.column_definition('StationNumber','Int64'),\n",
    "      sm.column_definition('Year','Int64'),\n",
    "      sm.column_definition('Month','Int64'),\n",
    "      sm.column_definition('Day','Int64'),\n",
    "      sm.column_definition('MaxTemp','Double'),\n",
    "      sm.column_definition('Quality','String(5)')]\n",
    "table_def=sm.table_definition(cols,'Processed',file_type='delta')\n",
    "\n",
    "files=['IDCJAC0010_009021_1800_Data.csv','IDCJAC0010_009106_1800_Data.csv','IDCJAC0010_009215_1800_Data.csv','IDCJAC0010_009225_1800_Data.csv',\n",
    "      'IDCJAC0010_009265_1800_Data.csv']\n",
    "for file in files:\n",
    "    df=pd.read_csv(file)\n",
    "    df.rename(columns={'Bureau of Meteorology station number':'StationNumber','Maximum temperature (Degree C)':'MaxTemp'},inplace=True)\n",
    "    df=df[['StationNumber', 'Year','Month','Day','MaxTemp','Quality']]\n",
    "    table_name='D3S_Training_%s_MaxTemp'%df['StationNumber'][0]\n",
    "    sm.create_table(sql_store_name,table_name,table_def)\n",
    "    sm.create_table(datalake_name,table_name,table_def)\n",
    "    sc.df_to_sql(sql_store_name,table_name,df)\n",
    "    print(\"Table %s written to sql\"%table_name)\n",
    "job = spm.submit_job('TransferFromSqlToDataLake','df2=df1',\n",
    "               import_tables=[spm.import_table('df1',sql_store_name,'D3S_Training_9021_MaxTemp')],\n",
    "               export_tables=[spm.export_table('df2',datalake_name,'D3S_Training_9021_MaxTemp')])\n",
    "for x in [9021,9106,9215,9225,9265]:\n",
    "    run=spm.run_job(job['JobId'],\n",
    "                'Test',\n",
    "                override_import_tables=[spm.import_table('df1',sql_store_name,'D3S_Training_%s_MaxTemp'%str(x))],\n",
    "                override_export_tables=[spm.export_table('df2',datalake_name,'D3S_Training_%s_MaxTemp'%str(x))])\n",
    "    while spm.list_runs(job['JobId'],run_id=run['RunId'])[0]['Status']=='Running':\n",
    "        time.sleep(5)\n",
    "    sm.delete_processed_table(sql_store_name,'D3S_Training_%s_MaxTemp'%str(x))\n",
    "    print(\"Table %s written to datalake and sql table deleted\"%x)\n",
    "spm.remove_job(job['JobId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and store reference table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create reference table\n",
    "ref_df=pd.DataFrame({'StationNumber':[9021,9106,9215,9225,9265],\n",
    "                     'StationName':['PERTH AIRPORT','GOSNELLS CITY','SWANBOURNE','PERTH METRO','HILLARYS BOAT HARBOUR NTC AWS'],\n",
    "                     'Lat':[-31.93,-32.05,-31.96,-31.92,-31.83],\n",
    "                     'Lon':[115.98,115.98,115.76,115.87,115.74]})\n",
    "cols=[sm.column_definition('StationNumber','Int64'),\n",
    "      sm.column_definition('StationName','String(50)'),\n",
    "      sm.column_definition('Lat','Double'),\n",
    "      sm.column_definition('Lon','Double')]\n",
    "table_def=sm.table_definition(cols,'Processed')\n",
    "sm.create_table(sql_store_name,'D3S_Training_WeatherStations',table_def)\n",
    "sc.df_to_sql(sql_store_name,'D3S_Training_WeatherStations',ref_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
